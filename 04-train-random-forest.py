"""
Random Forest Classifier Training for Rocky Reef Identification

This script trains two Random Forest models:
1. A multi-class classifier that distinguishes between all feature types 
   (Cloud, Coral reef, Open water, Rocky reef, Mangrove, Subtidal Rocky reef)
2. A binary classifier that identifies "Rocky reef" vs "Not Rocky reef"

We create both models for comparison purposes to see if separating the into multiple classes
allows the model to better characterise what is not a rocky reef and thus result in fewer
false positives.

The script:
- Loads pre-processed training data with Sentinel-2 spectral bands
- Trains both models on the same feature set with different Rocky reef weights
- Evaluates model performance with classification reports
- Saves models and their class mappings for later use in prediction

Input: CSV file containing training data with extracted pixel values from Sentinel-2 imagery
Output: Trained model files (.pkl) and class mapping files saved to the working directory
"""

import os
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
import joblib
import numpy as np

# Directory to save the trained models and class mappings
MODEL_DIR = r'working/training-data'

# Path to the CSV with extracted pixel values and training data
# Generated by the 02-extract-training-data.py script
INPUT_TRAINING_CSV_PATH = r'working/training-data/training-data-with-pixels.csv'

# List of weights to try for Rocky reef class
ROCKY_REEF_WEIGHTS = [1.0, 1.5, 2.0, 2.5, 3.0]

def main():
    
    # Load the data into a DataFrame
    df = pd.read_csv(INPUT_TRAINING_CSV_PATH)
    
    # Define the feature columns and target variable
    lt_false_color_feature_cols = ['S2_LT_B5', 'S2_LT_B8', 'S2_LT_B12']
    lt_true_color_feature_cols = ['S2_LT_B2', 'S2_LT_B3', 'S2_LT_B4']
    at_true_color_feature_cols = ['S2_AT_B2', 'S2_AT_B3', 'S2_AT_B4']
    all_feature_cols = lt_false_color_feature_cols + lt_true_color_feature_cols + at_true_color_feature_cols

    X = df[all_feature_cols].values
    y = df['FeatType'].values
    
    # Encode the categorical target labels into numeric values
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    
    # Find the index of the rocky reef class
    rocky_reef_index = np.where(le.classes_ == 'Rocky reef')[0][0]
    print(f"Rocky reef index: {rocky_reef_index}, Class name: {le.classes_[rocky_reef_index]}")
    
    # Count samples per class
    unique_classes, counts = np.unique(y, return_counts=True)
    class_counts = dict(zip(unique_classes, counts))
    print("Class distribution before balancing:")
    for cls, count in class_counts.items():
        print(f"  {cls}: {count}")
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)
    
    # Create binary labels (Rocky reef vs. Not Rocky reef)
    y_binary = np.zeros_like(y_encoded)
    y_binary[y_encoded == rocky_reef_index] = 1  # 1 for Rocky reef, 0 for everything else
    
    # Split the data for binary classification
    X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(
        X, y_binary, test_size=0.2, random_state=42, stratify=y_binary)
    
    
    
    # Train models with different weights
    for weight in ROCKY_REEF_WEIGHTS:
        print(f"\n\n===== Training models with Rocky reef weight: {weight} =====")

        # ------------ Multi-class Classification Model ------------
        print(f"\n--- Training Multi-class Model with weight={weight} ---")
        
        # Create class weights for multi-class model
        multi_class_weights = {i: 1.0 for i in range(len(le.classes_))}
        multi_class_weights[rocky_reef_index] = weight
        
        multi_rf = RandomForestClassifier(
            n_estimators=100, 
            random_state=42,
            class_weight=multi_class_weights,
            max_depth=10
        )
        multi_rf.fit(X_train, y_train)
        
        # Evaluate the multi-class model
        y_pred_multi = multi_rf.predict(X_test)
        print(f"Multi-class Classification Report (weight={weight}):")
        print(classification_report(y_test, y_pred_multi, target_names=le.classes_))
        

        # ------------ Binary Classification Model ------------
        print(f"\n--- Training Binary Model (Rocky reef vs. Not Rocky reef) with weight={weight} ---")

        # Setting the max_depth to 10 rather than None limits the depth of the trees
        # and thus how well they can fit the training data, helping to prevent overfitting.
        # Each tree in a Random Forest can create up to 2^(depth) leaf nodes, so
        # with a max depth of 10, each tree can create up to 1024 leaf nodes or about
        # 5 samples per leaf node with 5500 samples. Rocky reefs are approximately 20% of
        # the training data, so we can expect about 1100 samples in the rocky reef class.
        # For weight binary weight class of 3 for rocky reefs:
        # Hyperparameter tuning results: (5500 samples)
        # n_estimators max_depth Precision  Recall
        # 500          6         0.60       0.80
        # 500          8         0.65       0.78
        # 500          10        0.73       0.76
        # 500          12        0.79       0.73
        # 500          None      0.85       0.65
        # 100          6         0.60       0.81
        # 100          8         0.66       0.77
        # 100          10        0.73       0.75
        # 100          12        0.80       0.75
        # 100          None      0.85       0.65
        # 50           6         0.59       0.80
        # 50           8         0.65       0.77
        # 50           10        0.75       0.76
        # 50           12        0.80       0.72
        # 50           None      0.84       0.65
        # Conclusion: Going from 50 to 100 estimators improved the performance by about 1%,
        # Going from 100 to 500 made no improvement. A max depth of 10 balanced the precision and
        # recall.

        binary_class_weights = {
            0: 1,
            1: weight
        }

        binary_rf = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            class_weight=binary_class_weights,
            max_depth=10
        )

        binary_rf.fit(X_train_binary, y_train_binary)
        
        # Evaluate binary model
        y_pred_binary = binary_rf.predict(X_test_binary)
        
        print(f"Binary Classification Report (weight={weight}):")
        print(classification_report(y_test_binary, y_pred_binary, 
                                  target_names=["Not Rocky reef", "Rocky reef"]))
        
        # Save models with weight in the filename
        os.makedirs(MODEL_DIR, exist_ok=True)
        
        # Save multi-class model and encoder
        multi_model_path = os.path.join(MODEL_DIR, f'random_forest_model_multiclass_w{weight}.pkl')
        multi_mapping_path = os.path.join(MODEL_DIR, f'classes_mapping_multiclass_w{weight}.pkl')
        joblib.dump(multi_rf, multi_model_path)
        joblib.dump(le, multi_mapping_path)
        
        # Save binary model
        binary_model_path = os.path.join(MODEL_DIR, f'random_forest_model_binary_w{weight}.pkl')
        joblib.dump(binary_rf, binary_model_path)
        
        # Save binary model class mapping
        binary_mapping_path = os.path.join(MODEL_DIR, f'classes_mapping_binary_w{weight}.pkl')
        binary_le = LabelEncoder()
        binary_le.fit(["Not Rocky reef", "Rocky reef"])
        joblib.dump(binary_le, binary_mapping_path)
        
        print(f"Models with weight {weight} saved:")
        print(f"  Multi-class model: {multi_model_path}")
        print(f"  Multi-class mapping: {multi_mapping_path}")
        print(f"  Binary classifier: {binary_model_path}")
        print(f"  Binary mapping: {binary_mapping_path}")

if __name__ == '__main__':
    main()
